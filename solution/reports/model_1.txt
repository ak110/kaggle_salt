[INFO ] Accuracy: 0.956 <report_model_1:ml.py:532>
[INFO ] F1-score: 0.911 <report_model_1:ml.py:533>
[INFO ] AUC:      0.984 <report_model_1:ml.py:534>
[INFO ] Logloss:  0.123 <report_model_1:ml.py:535>
[INFO ] max score: 0.824 (threshold: 0.513) <report_model_1:evaluation.py:21>
[INFO ] scores: <report_model_1:evaluation.py:22>
[INFO ]   threshold=0.250: score=0.804 <report_model_1:evaluation.py:24>
[INFO ]   threshold=0.276: score=0.807 <report_model_1:evaluation.py:24>
[INFO ]   threshold=0.303: score=0.810 <report_model_1:evaluation.py:24>
[INFO ]   threshold=0.329: score=0.812 <report_model_1:evaluation.py:24>
[INFO ]   threshold=0.355: score=0.815 <report_model_1:evaluation.py:24>
[INFO ]   threshold=0.382: score=0.817 <report_model_1:evaluation.py:24>
[INFO ]   threshold=0.408: score=0.820 <report_model_1:evaluation.py:24>
[INFO ]   threshold=0.434: score=0.822 <report_model_1:evaluation.py:24>
[INFO ]   threshold=0.461: score=0.822 <report_model_1:evaluation.py:24>
[INFO ]   threshold=0.487: score=0.823 <report_model_1:evaluation.py:24>
[INFO ]   threshold=0.513: score=0.824 <report_model_1:evaluation.py:24>
[INFO ]   threshold=0.539: score=0.823 <report_model_1:evaluation.py:24>
[INFO ]   threshold=0.566: score=0.822 <report_model_1:evaluation.py:24>
[INFO ]   threshold=0.592: score=0.821 <report_model_1:evaluation.py:24>
[INFO ]   threshold=0.618: score=0.820 <report_model_1:evaluation.py:24>
[INFO ]   threshold=0.645: score=0.819 <report_model_1:evaluation.py:24>
[INFO ]   threshold=0.671: score=0.816 <report_model_1:evaluation.py:24>
[INFO ]   threshold=0.697: score=0.813 <report_model_1:evaluation.py:24>
[INFO ]   threshold=0.724: score=0.810 <report_model_1:evaluation.py:24>
[INFO ]   threshold=0.750: score=0.806 <report_model_1:evaluation.py:24>
