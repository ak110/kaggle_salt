[INFO ] Accuracy: 0.955 <report_model_small:ml.py:532>
[INFO ] F1-score: 0.907 <report_model_small:ml.py:533>
[INFO ] AUC:      0.983 <report_model_small:ml.py:534>
[INFO ] Logloss:  0.202 <report_model_small:ml.py:535>
[INFO ] max score: 0.802 (threshold: 0.268) <report_model_small:evaluation.py:21>
[INFO ] scores: <report_model_small:evaluation.py:22>
[INFO ]   threshold=0.100: score=0.795 <report_model_small:evaluation.py:24>
[INFO ]   threshold=0.142: score=0.799 <report_model_small:evaluation.py:24>
[INFO ]   threshold=0.184: score=0.801 <report_model_small:evaluation.py:24>
[INFO ]   threshold=0.226: score=0.802 <report_model_small:evaluation.py:24>
[INFO ]   threshold=0.268: score=0.802 <report_model_small:evaluation.py:24>
[INFO ]   threshold=0.311: score=0.802 <report_model_small:evaluation.py:24>
[INFO ]   threshold=0.353: score=0.802 <report_model_small:evaluation.py:24>
[INFO ]   threshold=0.395: score=0.802 <report_model_small:evaluation.py:24>
[INFO ]   threshold=0.437: score=0.802 <report_model_small:evaluation.py:24>
[INFO ]   threshold=0.479: score=0.802 <report_model_small:evaluation.py:24>
[INFO ]   threshold=0.521: score=0.801 <report_model_small:evaluation.py:24>
[INFO ]   threshold=0.563: score=0.800 <report_model_small:evaluation.py:24>
[INFO ]   threshold=0.605: score=0.799 <report_model_small:evaluation.py:24>
[INFO ]   threshold=0.647: score=0.798 <report_model_small:evaluation.py:24>
[INFO ]   threshold=0.689: score=0.796 <report_model_small:evaluation.py:24>
[INFO ]   threshold=0.732: score=0.795 <report_model_small:evaluation.py:24>
[INFO ]   threshold=0.774: score=0.793 <report_model_small:evaluation.py:24>
[INFO ]   threshold=0.816: score=0.790 <report_model_small:evaluation.py:24>
[INFO ]   threshold=0.858: score=0.786 <report_model_small:evaluation.py:24>
[INFO ]   threshold=0.900: score=0.781 <report_model_small:evaluation.py:24>
